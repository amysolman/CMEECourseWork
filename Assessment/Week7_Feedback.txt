Starting weekly assessment for Amy, Week7

Current Points = 100

Note that: 
(1) Major sections begin with a double "====" line 
(2) Subsections begin with a single "====" line 
(3) Code output or text file content are printed within single "*****" lines 

======================================================================
======================================================================
Your Git repo size this week is about 133.39 MiB on disk 

PART 1: Checking project workflow...

Found the following directories in parent directory: Week6, Week1, Week7, Assessment, Week5, Week2, Week9, Week4, .git, Miniproject, Week3, Project

Found the following files in parent directory: .gitignore, README.md, .DS_Store

Checking for key files in parent directory...

Found .gitignore in parent directory, great! 

Printing contents of .gitignore:
**********************************************************************
*~ 
*.tmp
**********************************************************************

Found README in parent directory, named: README.md

Printing contents of README.md:
**********************************************************************
# CMEE README

My CMEE Coursework Repository

This repository contains the coursework for my CMEE MRes at Imperial College London. The programs therein use shell scripting, python and R. 

Work is divided into week-specified subdirectories (Week1/Week2...) except for where indicated.

Week 1

Practicals using command line and shell scripting only. Sandbox contains practise files. Code contains shell scripts. Data contains data files used with shell scripts. Plus README.md. 

Week 2

Biological computing in Python I. Including: using data structures, writing code, control flow tools, comprehensions, debugging etc.

Week 3

Biological computing in R. Including: Variable types, data structures, manipulating data, control flow tools, vectorisation, data management and visualisation.

Week 4

Statistics in R. Including: Basic statistics for ecology and evolution, with a focus on applicability. Mostly parametric tests (descriptive statistics, t-test, ANOVA, correlations, linear models, hypothesis testing).

Week 5

Spatial Analyses and Geographic Information Systems. Including: GIS data types, obtaining and handling GIS data, creating maps, basic data analyses and hypothesis testing in the spatial domain.

Week 6

Genomics and Bioinformatics. Including: understanding genomic data collection methods, how to choose data collection technique, genomic databases, genetic structure within/between populations, how to characterise and interpret results of common analyses such as STRUCTURE and PCA.

Week 7

Biological Computing in Python II. Including: program testing, debugging and documentation, retrieving, managing and analyzing data from local and remote databases, automate file handling, string manipulation and run shell scripts, efficient numerical analyses, patching together R and Python scripts and functions.

Miniproject (Week 8)

Selected own dataset out of selection of three. Carried out computationally intensive analysis that includes elements of shell scripting, R & Python, addressing questions involving data processing and model fitting, writing up and compiling a meaningful report on the analysis.

Week 9

High Performance Computing. Including: develop an advanced understanding of programming in R, principles of High Performance Computing.

Project

Working folder for dissertation project, including project proposal.


**********************************************************************

======================================================================
Looking for the weekly directories...

Found 8 weekly directories: Week1, Week2, Week3, Week4, Week5, Week6, Week7, Week9

The Week7 directory will be assessed 

======================================================================
======================================================================
PART 2: Checking weekly code and workflow...

======================================================================
Assessing WEEK7...

Found the following directories: Code, Data, Results

Found the following files: README.md, .DS_Store

Checking for readme file in weekly directory...

Found README in parent directory, named: README.md

Printing contents of README.md:
**********************************************************************
# CMEE README WEEK 7

Biological Computing in Python II (11/11/19 - 15/11/19)
Including: program testing, debugging and documentation, retrieving, managing and analyzing data from local and remote databases, automate file handling, string manipulation and run shell scripts, efficient numerical analyses, patching together R and Python scripts and functions.
**********************************************************************

Found following files in results directory: outputFile.Rout, TestR.Rout, fmr_plot.pdf, LV_model2.pdf, LV_model4.pdf, LV_model.pdf, LV_model3.pdf, FW.pdf, TestR_errFile.Rout, errorFile.Rout, .DS_Store...
ideally, Results directory should be empty other than, perhaps, a readme. 

Found 15 code files: TestR.py, boilerplate.py, workflow.py, regexs.py, profileme2.py, timeitme.py, blackbirds.py, TestR.R, profileme.py, fmr.R, using_os.py, LV1.py, DrawFW.py, run_fmr_R.py, LV2.py

======================================================================
Testing script/code files...

======================================================================
Inspecting script file TestR.py...

File contents are:
**********************************************************************
#!/usr/bin/env python3
# Date: 14th November 2019

"""Using subprocess to use R and python together"""

__appname__ = 'TestR.py'
__author__ = 'Amy Solman (amy.solman19@imperial.ac.uk'
__version__ = '0.0.1'

#RUNNING R
#R is likely an importatn part of your project's analusis and data visualization components in particular
#For example for statistical analyses and pretty plotting (ggplot2)

import subprocess
subprocess.Popen("Rscript --verbose TestR.R > ../Results/TestR.Rout 2> ../Results/TestR_errFile.Rout", shell=True).wait()


#Now run TestR.py (or %cpaste) and check TestR.Rout and RestR_errorFile.Rout. #WHAT IS %CPASTE???

#Also, check what happens if you run (type directly into ipython or python console):

subprocess.Popen("Rscript --verbose NonExistScript.R > ../Results/outputFile.Rout 2> ../Results/errorFile.Rout", shell=True).wait()

#It is possible that the location of RScript is different in your Ubuntu install. To locate it,
#try find /usr -name 'Rscript' in the linux terminal (not in python!). 
#For example, you might need to specify the path to it using /usr/lib/R/bin/Rscript.

#What do you see on the screen? Now check outputFile.Rout and 'errorFile.Rout.**********************************************************************

Testing TestR.py...

TestR.py is a Python script file;

checking for docstrings...

Found no functions, but one docstring for the script, good

Current Points = 100

Output (only first 500 characters): 

**********************************************************************

**********************************************************************

Code ran without errors

Time consumed = 0.13396s

======================================================================
Inspecting script file boilerplate.py...

File contents are:
**********************************************************************
#!/usr/bin/env python3 - specifies location to python
# Tells the computer where to look for python
# Determines scripts ability to execute when part of a program

# Triple quotes start 'docstring' comment, describes operation of the script
# OR function/module within it
# Part of the running code in contrast to normal comments
# Access docstrings at run time
# Put at start
"""Description of this program or application.
    You can use several lines"""
# __ signal "internal" variables. Special variable names reserved
# By python for its own purposes


## imports ##
import sys # module to interface our program with the operating system
# allows you to be able to access modules from this program elsewhere using the module name

## constants ##

## functions ##
# def indicates start of a python function, all subsequent lines must be indented
# File containing function def and statements (assignments of constant variables) called modules
# argv = argument variable. A variable that holds the arguments you pass 
# to your Python script when you run it
# sys.argv object created by python using sys module (imported at beginning of script)
# that contains names of the argument variables in the current script

# This is the main function. Arguments obtained in the __name__ function
# Are fed to the main function
# if main function called only code in this module imported into other programs
# argv means arguments (values passed to a function) vector (transporter)
def main(argv): # defining main as a function and 
    """ Main entry point of the program """
    print('This is a boilerplate') # NOTE: indented used two tabs or 4 spaces
    return 0 # 0 means everything ran and has been fine. Hidden variable.

# Makes the file useable as a script as well as an importable moduel
# Directs python to set the special name variable (__name__) to have the value "__main__"
# This part means if you type the function name into command line
# it will action the module
if __name__ == "__main__":
    """Makes sure the "main" function is called from the command line"""
    status = main(sys.argv)
    sys.exit(status)
# Terminates the program in an explicit manner, returning appropriate status code
# Main () returns 0 on successful run
# sys.exit(status) returns zero - successful termination

**********************************************************************

Testing boilerplate.py...

boilerplate.py is a Python script file;

checking for docstrings...

Found one or more docstrings and functions

Current Points = 100

Output (only first 500 characters): 

**********************************************************************
This is a boilerplate

**********************************************************************

Code ran without errors

Time consumed = 0.02708s

======================================================================
Inspecting script file workflow.py...

File contents are:
**********************************************************************
#USING PYTHON TO BUILD WORKFLOWS

#You can use python to build an automated data analysis or simulation
#workflow that involves multiple languages, especially the ones
#you have already learnt: R, LATEX, UNIX bash
#For example, you could, in theory, write a single Python script
#to generate and update your masters dissertation, tables, plots, and all.
#Python is ideal for building such workflows because it
#has packages for practically every purpose.
#Thus this topic may be useful for your Miniproject, which will involve
#building a reproducible computational workflow.

#USING SUBPROCESS
#For building a workflow in Python the subprocess module is key.
#With this module you can run non-Python commands and scripts, obtain their outputs,
#and also crawl through and manipulate directories.

#First, import the module (this is part of the python standard lbrary
# so you won't need to install it)

import subprocess

#RUNNING PROCESSES
#There are two main ways to run commands through subprocess:
#'run' for basic usage, and 'Popen' (process open) for more advances usage.
#We will work directly with popen because run() is a wrapper around
#popen. Using popen directly gives more control over how the command is run,
#and how its input and output are processed.
#Let's try running some commands in the UNIX bash
#n a terminal, first cd to your code directory, launch ipython3, then and type:

p = subprocess.Popen(["echo", "I'm talkin' to you, bash!"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
#create object (p) - subprocess, process open - the lines you would usually type into terminal are entered here as strings "echo" and "I'm talking to you bash"
#stdout = output from the process created by command, in bytes, will need to be decoded
#stderr = error code to show if the process ran correctly
#PIPE = creates PIPE to "child process", sends the information from this command to the new command

#This creates an object p, from which you can extract the output and other information from the command you ran.
#Before we do anything more, let's look at our subprocess.popen call carefully.
#The command line arguments were passed as a list of strings, which avoids the need for escaping quotes or other
#special characters that might be interpreted by the shell (for example, in this case, there are apostrophes in the string
#that is being echoed in bash)
#stdout is the output from the process "spawned" by your command. This is bytes sequence (which you will need to decode - 
#more on this below)
#stderr is the error code (from which you can capture whether the process ran successfully or not). The method PIPE creates
#a new "pipe" to the "child process".

stdout, stderr = p.communicate()
stderr #nothing in this error code

#Nothing here, because the echo command does not return any code.
#The 'b' indicates that the output is in bites (unencoded).
#By default, stdout, stderr (and other outputs of p.communicate) are returned as binary (byte) format.
#Now check what's in stdout:

stdout #contains out message in bytes

#Let's encode and print it:
print(stdout.decode()) #decodes the bash command and prints

#You can also use a universal_newlines = True so that these outputs
#are returned as encoded text (default beng utf-8 usually), with line
#endings converted to '\n'.

#Let's try something else:
p = subprocess.Popen(["ls", "-l"], stdout=subprocess.PIPE)
stdout, stderr = p.communicate()
print (stdout.decode())
#Recall that the ls -l command lists all files in a long list format.

#You can also call python itself from bash (!):

p = subprocess.Popen(["python", "boilerplate.py"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
stdout, stderr = p.communicate()
print(stdout.decode())

#Similarly, to compile a LATEX document (using pdflatx in this case), you can
# do something like this:
# subprocess.os.system("pdflatex yourlatexdoc.tex")

# You can also do this instead:
########WHAT IS DIFFERENT ABOUT THESE?
p = subprocess.Popen(["python", "boilerplate.py"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
stdout, stderr = p.communicate()
print(stdout.decode()) 

#HANDLING DIRECTORY AND FILE PATHS

#You can also use subprocess.os to make your code OS (Linux, Windows, Mac) independent.
#For example, to assign paths:

subprocess.os.path.join('directory', 'subdirectory', 'file')

#Note that in all cases you can "catch" the output of subprocess so that you can then
#use the ouput within your python script. A simple example, where the output is a platform-dependent directory path, is:

MyPath = subprocess.os.path.join('amysolman', 'Documents', 'CMEECourseWork')
MyPath

#Explore what subprocess can do by tabbing subprocess., also for 
#submodules e.g. type subprocess.os. and then tab.**********************************************************************

Testing workflow.py...

workflow.py is a Python script file;

checking for docstrings...

No functions, but no script-level docstring either
2 pts deducted

Current Points = 98

Output (only first 500 characters): 

**********************************************************************
I'm talkin' to you, bash!

total 76
-rw-rw-r-- 1 mhasoba mhasoba 1924 Dec  3 05:59 blackbirds.py
-rw-rw-r-- 1 mhasoba mhasoba 2306 Dec  3 05:59 boilerplate.py
-rw-rw-r-- 1 mhasoba mhasoba 2564 Dec  3 05:59 DrawFW.py
-rwxrwxr-x 1 mhasoba mhasoba  866 Dec  3 05:59 fmr.R
-rw-rw-r-- 1 mhasoba mhasoba 2888 Dec  3 05:59 LV1.py
-rw-rw-r-- 1 mhasoba mhasoba 1351 Dec  3 05:59 LV2.py
-rw-rw-r-- 1 mhasoba mhasoba  679 Dec  3 05:59 profileme2.py
-rw-rw-r-- 1 mhasoba mhasoba 1243 Dec  3 05:59 profileme.py
drw
**********************************************************************

Code ran without errors

Time consumed = 0.05954s

======================================================================
Inspecting script file regexs.py...

File contents are:
**********************************************************************
#!/usr/bin/env python3
# Date: 14th November 2019

"""Script demonstrating regex in python"""

__appname__ = 'regexs.py'
__author__ = 'Amy Solman (amy.solman19@imperial.ac.uk'
__version__ = '0.0.1'

import re 
import csv

my_string = "a given string"

match = re.search(r'\s', my_string) #are there whitespaces?
print(match)

match.group()

match = re.search(r'\d', my_string) #are there numbers?
print(match)

MyStr = 'an example'

match = re.search(r'\w*\s', MyStr) #match a single character (zero or more times) with a whitespace 
if match:
    print('found a match:', match.group())
else:
    print('did not find a match')

match = re.search(r'2' , "it takes 2 to tango") #search for the number 2!
match.group()

match = re.search(r'\d' , "it takes 2 to tango") #find a numeric character
match.group()

match = re.search(r'\d.*' , "it takes 2 to tango") #find a numeric and everything after up until new line
match.group()

match = re.search(r'\s\w{1,3}\s', 'once upon a time') #find a space followed by a single character (matches 1-3 times) and then another space
match.group()
#basically, find a space, followed by 1 to 3 letters and then another space

match = re.search(r'\s\w*$', 'once upon a time')
match.group()
#predicted output = ' time' CORRECT

#LEt's switch to a more compact syntax by directly returning the matched group
#(by directly appening .group() to the result)

re.search(r'\w*\s\d.*\d', 'take 2 grams of H2O').group()
#predicted output = 'take 2 grams of H2' CORRECT!

re.search(r'^\w*.*\s', 'once upon a time').group()
#predicted output = 'once ' WRONG! 'once upon a '
#find the start of the string a character (0+) match any character except linebreak (0+) with whitespace
#from the beginning of the string match any word with proceeding linebreak

# *, + and {} repeat previous regex token as many times as possible
#They may match more text than you want. To terminate at the first found
#instance of a pattern use ?

re.search(r'^\w*.*?\s', 'once upon a time').group()
#predicted output = from the beginning of the string match the FIRST word with proceeding whitespace
# = 'once '

#Let's try matching a HTML tag

re.search(r'<.+>', 'This is a <EM>first</EM> test').group()
#predicted output = '<EM>' WRONG
# = '<EM>first</EM>

#Because + is greedy - instead, we can make + 'lazy'
re.search(r'<.+?>', 'This is a <EM>first</EM> test').group()

re.search(r'\d*\.?\d*', '1432.75+60.22i').group()
#predicted output = '1432.75' CORRECT!

re.search(r'[AGTC]+', 'the sequence ATTCGT').group()
#Search for these characters 

re.search(r'\s+[A-Z]\w+\s*\w+', "The bird-shit frog's name is Theloderma asper.").group()
#Search for a space one or more times followed by capital characters A-Z then all characters then a space then all characters

#How about looking for email addresses in a string? For example, let's try matching
#a string consisting of an academic's name, email address and research area
#or interest

MyStr = 'Samraat Pawar, s.pawar@imperial.ac.uk, Systems biology and ecological theory'
match = re.search(r"[\w\s]+,\s[\w\.@]+,\s[\w\s]+", MyStr)
match.group()
#Search for any word then space multiple times comma space then characters dot @ multiple times
#comma space characters space multiple times
#[] ensures any combination of characters and spaces is found

MyStr = 'Samraat Pawar, s-pawar@imperial.ac.uk, Systems biology and ecological theory'
match = re.search(r"[\w\s]+,\s[\w\.@]+,\s[\w\s&]+", MyStr)
#match.group()
#Error here because we don't have a '.' in the email address
#Let's make the email address part of the regex more robust

match = re.search(r"[\w\s]+,\s[\w.-]+@[\w\.-]+,\s[\w\s&]+", MyStr)
match.group()
#Includes any combination of characters '.' and '-'

#Practicals: Some RegExercises

#The following exercises are not fro submission as part of your coursework, 
#but we will discuss them in class on a subsequent day

#1. Try the regex we used above for finding names for cases where the person's name has 
#something unexpected like a ? or a +. Does it work? How can you make it more robust?

name = 'Andy? Pu++er'
match = re.search(r"[\w\s\?\+]+", name)
match.group()

#2. Translate the following regular expressions into regular English

#r'^abc[ab]+\s\t\d' Search at the start of the string for abc exactly 
# then any combination of ab repeatedly, then a space, then a tab, then a number

#r'^\d{1,2}\/\d{1,2}\/\d{4}$' Search at the start of the string for 1 to 2 numbers,
#then a /, then 1 to 2 numbers, then a /, then 4 numbers at the end of the string - A DATE!

#r'\s*[a-zA-z,\s]+\s*' #Search for a space zero or more times, followed by lowercase/
#uppercase letters, commas and spaces in any order, multiple times, followed by a space zero or more times

#3. Write a regex to match dates in format YYYYMMDD, making sure that:
#Only seemingly valid dates match (i.e. year greater than 1900)
#First digit in month is either 0 or 1
#First digit in dat <= 3

right_date = '19901112'
wrong_date = '39901172'
otherdate = '294746583930300'
match = re.search(r'^[1|2][0-9][0-9][0-9][0-1][0-9][0-3][0-9]$', right_date)
if match:
    print('Correct format date:', match.group())
#elif: 
#    print("fail")


#Grouping regex patterns

#You can group regex patterns into meaningful blocks using parentheses.
#Let's look again at the example of finding email addresses.

MyStr = 'Samraat Pawar, s.pawar@imperial.ac.uk, Systems biology and ecological theory'
match = re.search(r"[\w\s]+,\s[\w\.-]+@[\w\.-]+,\s[\w\s&]+",MyStr)
#match.group()
match.group(0)

#Now create groups using ( ):
match = re.search(r"([\w\s]+),\s([\w\.-]+@[\w\.-]+),\s([\w\s&]+)", MyStr)
if match:
    print(match.group(0)) #print the whole thing
    print(match.group(1)) #print first group
    print(match.group(2)) #print second group
    print(match.group(3)) #print third group

#Finding all matches

#Above we used re.search() to find the first match for a pattern. In many scenarios,
#you will need to find all the matches of a pattern.
#The function re.findall() does precisely this and returns all matches as a list
#of strings, with each string representing one match.

#Let's try this on an extension of the email example above for some data with multiple addresses:

MyStr = MyStr = "Samraat Pawar, s.pawar@imperial.ac.uk, Systems biology and ecological theory; Another academic, a-academic@imperial.ac.uk, Some other stuff thats equally boring; Yet another academic, y.a_academic@imperial.ac.uk, Some other stuff thats even more boring"

#Now re.findall() returns a list of all emails found:

emails = re.findall(r'[\w\.-]+@[\w\.-]+', MyStr)
for email in emails:
    print(email)

#Finding in files

#You will generslly be wanted to apply regex searches to while files.
#You might be tempted to write a loop to iterate over the lines of the file, calling
#re.findall() on each line. However, re.findall() can return a lst of
#all the matches in a single step.

#Let's try finding all species names that correspong to Oaks in a datafile.
f = open('../Data/TestOaksData.csv')
found_oaks = re.findall(r"Q[\w\s].*\s", f.read())

found_oaks #This words because recall that f.read() returns the whole text of a file
#in a single string. Also, the file is closed after reading.

#GROUPS WITH MULTIPLE MATCHES

#Grouping pattern matches using ( ) as you learned above, can be combined with re.findall()
#IF the pattern includes TWO OR MORE groups, then instead of returning a list of strings,
#re.findall() returns a a list of tuples.
#Each tuplerepresents one match of the pattern, and inside the tuple is group(1), group(2) etc.
#Let's try it:

MyStr = "Samraat Pawar, s.pawar@imperial.ac.uk, Systems biology and ecological theory; Another academic, a-academic@imperial.ac.uk, Some other stuff thats equally boring; Yet another academic, y.a_academic@imperial.ac.uk, Some other stuff thats even more boring"

found_matches = re.findall(r"([\w\s]+),\s([\w\.-]+@[\w\.-]+)", MyStr)
found_matches

for item in found_matches:
    print(item)

#EXTRACTING TEXT FROM WEBPAGES

#Ok, let's step up the ante here. How about extracting text from a web page to create your own data?
#You will need a new package urllib3. Install it and import it.

import urllib3

conn = urllib3.PoolManager() #open a connection
r = conn.request('GET', 'http://www.imperial.ac.uk/silwood-park/academic-staff/')
webpage_html = r.data #read in the webpage's contents
#Wouldn't work at first, changed https to http

#This is returned as bytes (not strings)
type(webpage_html)

#So decode it (remember, the default decoding that this method applies is utf-8):
My_Data = webpage_html.decode()
#print(My_Data)

#That's a lot of potentially useful information! Let's extract all the names of academics:
pattern = r"Dr\s+\w+\s+\w+"
regex = re.compile(pattern) #example use of re.compile(); you can also ignore case with re.IGNORECASE
for match in regex.finditer(My_Data): #example of use of re-finditer()
    print(match.group())

#Again, nice! However, it's not perfect. You can improve this by:
#Extracting Prof names as well
#Eliminating the repeated matches

pattern2= r"(Prof\s+\w+\s+\w+|Dr\s+\w+\s+\w+)(?!.*\1)"
regex2 = re.compile(pattern2)
for match in regex2.finditer(My_Data):
    print(match.group())

####ASK ABOUT THIS IN THE MORNING
#Grouping to seperate title from first and second names
#Extracting names that have unexpected characters (e.g. "O'Gorman", which are currently not being matched properly)
pattern3= r"(Prof\s+[\w+'*\s+\w+\-]|Dr\s+[\w+'*\s+\w+\-])(?!.*\1)"
regex3 = re.compile(pattern2)
for match in regex3.finditer(My_Data):
    print(match.group())

#REPLACING TEXT
#Using the same web page data, let's try using the re-sub command on the same web page data (My_Data)
#to replace text

New_Data = re.sub(r'\t'," ", My_Data) #replace all tabs with a space
    **********************************************************************

Testing regexs.py...

regexs.py is a Python script file;

checking for docstrings...

Found no functions, but one docstring for the script, good

Current Points = 98

Output (only first 500 characters): 

**********************************************************************
<_sre.SRE_Match object; span=(1, 2), match=' '>
None
found a match: an 
Correct format date: 19901112
Samraat Pawar, s.pawar@imperial.ac.uk, Systems biology and ecological theory
Samraat Pawar
s.pawar@imperial.ac.uk
Systems biology and ecological theory
s.pawar@imperial.ac.uk
a-academic@imperial.ac.uk
y.a_academic@imperial.ac.uk
('Samraat Pawar', 's.pawar@imperial.ac.uk')
(' Another academic', 'a-academic@imperial.ac.uk')
(' Yet another academic', 'y.a_academic@imperial.ac.uk')
Dr Arkhat Abzhanov
**********************************************************************

Code ran without errors

Time consumed = 0.35583s

======================================================================
Inspecting script file profileme2.py...

File contents are:
**********************************************************************
#!/usr/bin/env python3
# Date: 11th November 2019

"""Script profiling functions"""

__appname__ = 'profileme2.py'
__author__ = 'Amy Solman (amy.solman19@imperial.ac.uk'
__version__ = '0.0.1'

def my_squares(iters):
    out = [i ** 2 for i in range(iters)] #loops has been converted to list comprehension
    return out

#try preallocating a numpy array for my_squares instead of using a list

def my_join(iters, string):
    out = ''
    for i in range(iters):
        out += ", " + string #replaced .join with explicit string concatenation
    return out

def run_my_funcs(x,y):
    print(x,y)
    my_squares(x)
    my_join(x,y)
    return 0

run_my_funcs(10000000,"My string")**********************************************************************

Testing profileme2.py...

profileme2.py is a Python script file;

checking for docstrings...

Found one or more docstrings and functions

Missing docstring, either in one or functions and/or at the script level

Current Points = 96.5

Output (only first 500 characters): 

**********************************************************************
10000000 My string

**********************************************************************

Code ran without errors

Time consumed = 3.62488s

======================================================================
Inspecting script file timeitme.py...

File contents are:
**********************************************************************
#!/usr/bin/env python3
# Date: 11th November 2019

"""Script for timing functions"""

__appname__ = 'timeitme.py'
__author__ = 'Amy Solman (amy.solman19@imperial.ac.uk'
__version__ = '0.0.1'
###########################################################
# loops vs. list comprehension: which is faster?
###########################################################

iters = 1000000

import timeit #import the timeit module

from profileme import my_squares as my_squares_loops #from our first script import the slower module
from profileme2 import my_squares as my_squares_lc #from our second script import the faster module

# %timeit my_squares_loops(iters)
# %timeit my_squares_lc(iters)

###########################################################
# loops vs. the join method for strings: which is faster?
###########################################################

mystring = "my string"

from profileme import my_join as my_join_join
from profileme2 import my_join as my_join 

# %timeit(my_join_join(iters, mystring))
# %timeit(my_join(iters, mystring))

**********************************************************************

Testing timeitme.py...

timeitme.py is a Python script file;

checking for docstrings...

Found no functions, but one docstring for the script, good

Current Points = 96.5

Output (only first 500 characters): 

**********************************************************************

**********************************************************************

Code ran without errors

Time consumed = 10.00699s

======================================================================
Inspecting script file blackbirds.py...

File contents are:
**********************************************************************
#!/usr/bin/env python3
# Date: 14th November 2019

"""Blackbird practical for Python II"""

__appname__ = 'blackbirds.py'
__author__ = 'Amy Solman (amy.solman19@imperial.ac.uk'
__version__ = '0.0.1'
import re

# Read the file (using a different, more python 3 way, just for fun!)
#with open('../data/blackbirds.txt', 'r') as f:
#    text = f.read()

f = open('../Data/blackbirds.txt', 'r')
blackbirds = f.read()
print(blackbirds)
# replace \t's and \n's with a spaces:
#text = text.replace('\t',' ')
#text = text.replace('\n',' ')
# You may want to make other changes to the text. 

blackbirds = re.sub(r'\t|\n'," ", blackbirds)
print(blackbirds)

# In particular, note that there are "strange characters" (these are accents and
# non-ascii symbols) because we don't care for them, first transform to ASCII:

#text = text.encode('ascii', 'ignore') # first encode into ascii bytes
#text = text.decode('ascii', 'ignore') # Now decode back to string

blackbirds = blackbirds.encode('ascii', errors='ignore').decode('ascii', errors='ignore')


# Now extend this script so that it captures the Kingdom, Phylum and Species
# name for each species and prints it out to screen neatly.

# Hint: you may want to use re.findall(my_reg, text)... Keep in mind that there
# are multiple ways to skin this cat! Your solution could involve multiple
# regular expression calls (easier!), or a single one (harder!)

#kingdoms = re.findall(r'Kingdom\s+\w+\s+\w+\,\s+\w+\,\s+\w+', blackbirds)
#for kingdom in kingdoms:
#    print(kingdom)
#phylums = re.findall(r'Phylum\s+\w+\s+\w+\,\s+\w+\,\s+\w+', blackbirds)
#for phyla in phylums:
#    print(phyla)
#species = re.findall(r'Species\s+\w+\s+\w+', blackbirds)
#for specie in species:
#    print(specie)


blackbirds_sorted = re.findall(r"Kingdom\s+\w+\s+\w+\,\s+\w+\,\s+\w+|Phylum\s+\w+\s+\w+\,\s+\w+\,\s+\w+|Species\s+\w+\s+\w+", blackbirds)
for birds in blackbirds_sorted:
    print(birds)

**********************************************************************

Testing blackbirds.py...

blackbirds.py is a Python script file;

checking for docstrings...

Found no functions, but one docstring for the script, good

Current Points = 96.5

Output (only first 500 characters): 

**********************************************************************
Taxonomic Hierarchy
 	 	 	 
 	Kingdom	Animalia  – Animal, animaux, animals	 
 	   Phylum	Chordata  – cordés, cordado, chordates	 
 	      Subphylum	Vertebrata  – vertebrado, vertébrés, vertebrates	 
 	         Class	Aves  – Birds, oiseaux	 
 	            Order	Passeriformes  – Perching Birds, passereaux	 
 	               Family	Icteridae  – American Blackbirds, Orioles, New World Blackbirds	 
 	                  Genus	Euphagus Cassin, 1867 – American Blackbirds	 
 	                     Species	E
**********************************************************************

Code ran without errors

Time consumed = 0.03032s

======================================================================
Inspecting script file TestR.R...

File contents are:
**********************************************************************
print("Hello, this is R!")
**********************************************************************

Testing TestR.R...

Output (only first 500 characters): 

**********************************************************************
[1] "Hello, this is R!"

**********************************************************************

Code ran without errors

Time consumed = 0.09717s

======================================================================
Inspecting script file profileme.py...

File contents are:
**********************************************************************
#!/usr/bin/env python3
# Date: 11th November 2019

"""Script for profiling functions/"""

__appname__ = 'profileme.py'
__author__ = 'Amy Solman (amy.solman19@imperial.ac.uk'
__version__ = '0.0.1'

def my_squares(iters): #create a function that takes the argument 'iters'
    out = [] #create empty vector
    for i in range(iters): #for each item in range of the given argument
        out.append(i ** 2) #add to our empty vector item squared
    return out #give us the content of the vector
    
def my_join(iters, string): #create a vector that takes two arguments, 'iters' and 'string'
    out = '' #create empty string
    for i in range(iters): #for each item in range of the given argument
        out += string.join(", ") # add the string argument to the empty string
    return out #give us the content of the string

def run_my_funcs(x,y): #create funtion that takes two arguments 'x' and 'y'
    print(x,y) #print the two given arguments
    my_squares(x) #run my_squares function with 'x' as the 'iters' argument
    my_join(x,y) #run my_join function with 'x' and 'y' as the 'iters' and 'string' argument
    return 0 

run_my_funcs(10000000,"My string")

# run -p profileme.py - this will profile the functions within the script
**********************************************************************

Testing profileme.py...

profileme.py is a Python script file;

checking for docstrings...

Found one or more docstrings and functions

Missing docstring, either in one or functions and/or at the script level

Current Points = 95.0

Output (only first 500 characters): 

**********************************************************************
10000000 My string

**********************************************************************

Code ran without errors

Time consumed = 6.44558s

======================================================================
Inspecting script file fmr.R...

File contents are:
**********************************************************************
# Amy Solman amy.solman19@imperial.ac.uk
# 15th November 2019
# fmr.R
# Plots log(field metabolic rate) against log(body mass) for the Nagy et al 
# 1999 dataset to a file fmr.pdf.
# Writes the list of species names to species.csv

cat("Reading CSV\n") #print reading csv

nagy <- read.csv('../Data/NagyEtAl1999.csv', stringsAsFactors = FALSE) #read in the csv data

cat("Creating graph\n") #print creating graph
pdf('../Results/fmr_plot.pdf', 11, 8.5) #create pdf plotting results, with size of
col <- c(Aves='purple3', Mammalia='red3', Reptilia='green3') #
plot(log10(nagy$M.g), log10(nagy$FMR.kJ.day.1), pch=19, col=col[nagy$Class], 
     xlab=~log[10](M), ylab=~log[10](FMR))
for(class in unique(nagy$Class)){
    model <- lm(log10(FMR.kJ.day.1) ~ log10(M.g), data=nagy[nagy$Class==class,])
    abline(model, col=col[class])
}
dev.off()

cat("Finished in R!\n")
**********************************************************************

Testing fmr.R...

Output (only first 500 characters): 

**********************************************************************
Reading CSV
Creating graph
null device 
          1 
Finished in R!

**********************************************************************

Code ran without errors

Time consumed = 0.16806s

======================================================================
Inspecting script file using_os.py...

File contents are:
**********************************************************************
#!/usr/bin/env python3
# Date: 15th November 2019

"""Subprocess practical for Python II"""

__appname__ = 'using_os.py'
__author__ = 'Amy Solman (amy.solman19@imperial.ac.uk'
__version__ = '0.0.1'

# Use the subprocess.os module to get a list of files and directories 
# in your ubuntu home directory 

# Hint: look in subprocess.os and/or subprocess.os.path and/or 
# subprocess.os.walk for helpful functions

import subprocess, pathlib, re

subprocess.Popen(["ls", "-l"], cwd=pathlib.Path.home())

#################################
#~Get a list of files and 
#~directories in your home/ that start with an uppercase 'C'

# Type your code here:

# Get the user's home directory.
home = subprocess.os.path.expanduser("~")

# Create a list to store the results.
FilesDirsStartingWithC = []

# Use a for loop to walk through the home directory.
for (dir, subdir, files) in subprocess.os.walk(home):
        FilesDirsStartingWithC.extend(re.findall(r'^C\w+', ''.join(dir)))
        FilesDirsStartingWithC.extend(re.findall(r'^C\w+', ''.join(subdir)))
        FilesDirsStartingWithC.extend(re.findall(r'^C\w+', ''.join(files)))
print(FilesDirsStartingWithC)

#################################
# Get files and directories in your home/ that start with either an 
# upper or lower case 'C'

# Type your code here:
home = subprocess.os.path.expanduser("~")
FilesDirsStartingWithCc = []
for (dir, subdir, files) in subprocess.os.walk(home):
        FilesDirsStartingWithCc.extend(re.findall(r'^C\w+|^c\w+', ''.join(dir)))
        FilesDirsStartingWithCc.extend(re.findall(r'^C\w+|^c\w+', ''.join(subdir)))
        FilesDirsStartingWithCc.extend(re.findall(r'^C\w+|^c\w+', ''.join(files)))
print(FilesDirsStartingWithCc)

#################################
# Get only directories in your home/ that start with either an upper or 
#~lower case 'C' 

# Type your code here:
home = subprocess.os.path.expanduser("~")
DirsStartingWithCc = []
for (dir, subdir, files) in subprocess.os.walk(home):
        DirsStartingWithCc.extend(re.findall(r'^C\w+|^c\w+', ''.join(dir)))
        DirsStartingWithCc.extend(re.findall(r'^C\w+|^c\w+', ''.join(subdir)))
print(DirsStartingWithCc)**********************************************************************

Testing using_os.py...

using_os.py is a Python script file;

checking for docstrings...

Found no functions, but one docstring for the script, good

Current Points = 95.0

Output (only first 500 characters): 

**********************************************************************

**********************************************************************

Encountered error (or warning):
Traceback (most recent call last):
  File "using_os.py", line 18, in <module>
    subprocess.Popen(["ls", "-l"], cwd=pathlib.Path.home())
  File "/usr/lib/python3.5/subprocess.py", line 947, in __init__
    restore_signals, start_new_session)
  File "/usr/lib/python3.5/subprocess.py", line 1490, in _execute_child
    restore_signals, start_new_session, preexec_fn)
TypeError: Can't convert 'PosixPath' object to str implicitly

======================================================================
Inspecting script file LV1.py...

File contents are:
**********************************************************************
#!/usr/bin/env python3
# Date: 11th November 2019

"""Script ploting output of Lokta-Volterra model"""

__appname__ = 'LV1.py'
__author__ = 'Amy Solman (amy.solman19@imperial.ac.uk'
__version__ = '0.0.1'

import scipy as sc

import scipy.integrate as integrate

import matplotlib.pylab as p

#Now define a function that returns the growth rate of consumer and resource population at any give time step.
def dCR_dt(pops, t=0):

    R = pops[0]
    C = pops[1]
    dRdt = r * R - a * R * C
    dCdt = -z * C + e * a * R * C

    return sc.array([dRdt, dCdt])

type(dCR_dt)

#So dCR_dt has been stored as a function object in teh current Python session, all ready to go.
#Now assign some parameter values:

r = 1. #growth rate of resource pop
a = 0.1 #search rate for resource
z = 1.5 #mortality rate
e = 0.75 #consumers efficiency converting resource to consumer biomass

#Define the time vector; let's integrate from time point 0 to 15, using 1000 sub-divisions of time:

t = sc.linspace(0, 15, 1000) #sc.linspace = return evenly spaced numbers over a
#specified interval from x to y with z subdivisions
#Note that the units of time are arbitrary here.
#Set the initial conditions for the two populations (10 resources and 5 consumers per unit area)
#and convert the two into an array (because our dCR_dt function takes an array as input)

R0 = 10
C0 = 5
RC0 = sc.array([R0, C0])

#Now numerically integrate this system forward from those starting conditions:

pops, infodict = integrate.odeint(dCR_dt, RC0, t, full_output = True)
pops
#So pops contains the result (the population trajectories).
#Also check what's in infodict (it's a dictionary with additional information).
type(infodict)
infodict.keys()
#check what the infodict output is by reading the help documentation with ?scipy.integrate.odeint.
#For example, you can return a message to screen about whether the integration was successful:
infodict['message']
infodict['hu']
#So it worked, great! But we would like to visualize the results. LEt's do it using the matplotlib package.

#PLOTTING IN PYTHON
#To visualize the results of your numerical simulations in Python (or for data exploration/analyses),
#you can use matplotlib which uses Matlab like plotting syntax.
#First let's import the package:

#Now open an empty figure object (analogous to an R graphics object)

f1 = p.figure()
p.plot(t, pops[:,0], 'g-', label='Resource density') #Plot
p.plot(t, pops[:,1], 'b-', label = 'Consumer densioty')
p.grid()
p.legend(loc='best')
p.xlabel('Time')
p.ylabel('Population density')
p.title('Consumer-Resource population dynamics')

#Finally, save the figure as a pdf:

f1.savefig('../results/LV_model.pdf') #save figure

f2 = p.figure()
p.plot(pops[:,0], pops[:,1], 'r-')
p.grid()
p.xlabel('Resource density')
p.ylabel('Consumer density')
p.title('Consumer-Resource population dynamics')

f2.savefig('../results/LV_model2.pdf')**********************************************************************

Testing LV1.py...

LV1.py is a Python script file;

checking for docstrings...

Found one or more docstrings and functions

Missing docstring, either in one or functions and/or at the script level

Current Points = 94.5

Output (only first 500 characters): 

**********************************************************************

**********************************************************************

Encountered error (or warning):
Traceback (most recent call last):
  File "LV1.py", line 80, in <module>
    f1.savefig('../results/LV_model.pdf') #save figure
  File "/usr/local/lib/python3.5/dist-packages/matplotlib/figure.py", line 1814, in savefig
    self.canvas.print_figure(fname, **kwargs)
  File "/usr/local/lib/python3.5/dist-packages/matplotlib/backend_bases.py", line 2259, in print_figure
    **kwargs)
  File "/usr/local/lib/python3.5/dist-packages/matplotlib/backends/backend_pdf.py", line 2584, in print_pdf
    file = PdfFile(filename, metadata=kwargs.pop("metadata", None))
  File "/usr/local/lib/python3.5/dist-packages/matplotlib/backends/backend_pdf.py", line 439, in __init__
    fh = open(filename, 'wb')
FileNotFoundError: [Errno 2] No such file or directory: '../results/LV_model.pdf'

======================================================================
Inspecting script file DrawFW.py...

File contents are:
**********************************************************************
#!/usr/bin/env python3
# Date: 13th November 2019

"""Script generating synthetic food web"""

__appname__ = 'DrawFW.py'
__author__ = 'Amy Solman (amy.solman19@imperial.ac.uk'
__version__ = '0.0.1'

import networkx as nx
import scipy as sc 
import matplotlib.pylab as p 

#Let's generate a synthetic food web. We can do this with the following function that generates
#a random adjacency list of a N-species food web with connectance probability C:
#the probability of having a linkbetween any pair of species in the food web.

def GenRdmAdjList(N= 2, C = 0.5):
    """
    """
    Ids = range(N)
    ALst = []
    for i in Ids:
        if sc.random.uniform(0, 1, 1) < C:
            Lnk = sc.random.choice(Ids,2).tolist()
            if Lnk[0] != Lnk: #avoid self (e.g. cannibalistic) loops
                ALst.append(Lnk)
    return ALst

#Note that we are using a uniform random distribution between [0,1]
#to generate a connectance probability between each species pair.

#Now assign number of species (MaxN) and connectance (C):

MaxN = 30
C = 0.75

#Now generate an adjacency list representing a random food web:
AdjL = sc.array(GenRdmAdjList(MaxN, C))
AdjL

#So that's what an adjacency list looks like. The two columns of numbers correspond to the 
#consumer and resource ids, respectively.
#Now generate species (node) data:

Sps = sc.unique(AdjL) #get species ids

#Now generate body sizes for the species. We will use a log10 scale because species body
#sizes tend to be log-normally distributed.

SizRan = ([-10,10]) #use log10 scale
Sizs = sc.random.uniform(SizRan[0],SizRan[1],MaxN)
Sizs

#Let's visualize the size distribution we have generated.

p.hist(Sizs) #log10 scale

p.hist(10 ** Sizs) #raw scale

#Let's now plot the network, with node sizes proportional to (log) body size.

p.close('all') #close all open plot objects

#Let's use a circular configuration. For this, we need to calculate the coordinates,
#easily done using networkx:

pos = nx.circular_layout(Sps)

#See networkx.layout for inbuilt functions to compute other types of node coordinates.
#Now generate a networkx graph object:

G = nx.Graph()

#Now add the nodes and links (edges) to it:

G.add_nodes_from(Sps)
G.add_edges_from(tuple(AdjL))

#Note that the function add_edges_from needs the adjacency list as a tuple.
#Now generate node sizes that are proportional to (log) body sizes:

NodSizs = 1000 * (Sizs-min(Sizs))/(max(Sizs)-min(Sizs))

#Now render (plot) the graph:

f1 = p.figure()
nx.draw_networkx (G, pos, node_size = NodSizs)

f1.savefig('../results/FW.pdf')



**********************************************************************

Testing DrawFW.py...

DrawFW.py is a Python script file;

checking for docstrings...

Found one or more docstrings and functions

Current Points = 94.5

Output (only first 500 characters): 

**********************************************************************

**********************************************************************

Encountered error (or warning):
/usr/lib/python3/dist-packages/networkx/drawing/nx_pylab.py:522: MatplotlibDeprecationWarning: The is_string_like function was deprecated in version 2.1.
  if not cb.is_string_like(edge_color) \
/usr/lib/python3/dist-packages/networkx/drawing/nx_pylab.py:543: MatplotlibDeprecationWarning: The is_string_like function was deprecated in version 2.1.
  if cb.is_string_like(edge_color) or len(edge_color) == 1:
/usr/lib/python3/dist-packages/networkx/drawing/nx_pylab.py:724: MatplotlibDeprecationWarning: The is_string_like function was deprecated in version 2.1.
  if not cb.is_string_like(label):
Traceback (most recent call last):
  File "DrawFW.py", line 90, in <module>
    f1.savefig('../results/FW.pdf')
  File "/usr/local/lib/python3.5/dist-packages/matplotlib/figure.py", line 1814, in savefig
    self.canvas.print_figure(fname, **kwargs)
  File "/usr/local/lib/python3.5/dist-packages/matplotlib/backend_bases.py", line 2259, in print_figure
    **kwargs)
  File "/usr/local/lib/python3.5/dist-packages/matplotlib/backends/backend_pdf.py", line 2584, in print_pdf
    file = PdfFile(filename, metadata=kwargs.pop("metadata", None))
  File "/usr/local/lib/python3.5/dist-packages/matplotlib/backends/backend_pdf.py", line 439, in __init__
    fh = open(filename, 'wb')
FileNotFoundError: [Errno 2] No such file or directory: '../results/FW.pdf'

======================================================================
Inspecting script file run_fmr_R.py...

File contents are:
**********************************************************************
#!/usr/bin/env python3
# Date: 15th November 2019

"""Runs fmr.R to generate desired pdf plot"""

__appname__ = 'run_fmr_R.py'
__author__ = 'Amy Solman (amy.solman19@imperial.ac.uk'
__version__ = '0.0.1'


import subprocess

p = subprocess.Popen(["Rscript", "fmr.R"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
stdout, stderr = p.communicate()
print(stdout.decode())
if p.returncode == 0:
    print('Run successful! Well done! Goldstar!')

#run_fmr_R.py should also print to the python screen whether the run was successful, and the contents of the R console output**********************************************************************

Testing run_fmr_R.py...

run_fmr_R.py is a Python script file;

checking for docstrings...

Found no functions, but one docstring for the script, good

Current Points = 94.5

Output (only first 500 characters): 

**********************************************************************
Reading CSV
Creating graph
null device 
          1 
Finished in R!

Run successful! Well done! Goldstar!

**********************************************************************

Code ran without errors

Time consumed = 0.19989s

======================================================================
Inspecting script file LV2.py...

File contents are:
**********************************************************************
#!/usr/bin/env python3
# Date: 16th November 2019

"""Script ploting output of Lokta-Volterra model"""

__appname__ = 'LV2.py'
__author__ = 'Amy Solman (amy.solman19@imperial.ac.uk)'
__version__ = '0.0.1'

import scipy as sc
import scipy.integrate as integrate
import matplotlib.pylab as p
from sys import argv
script, first, second, third, fourth = argv

#Now define a function that returns the growth rate of consumer and resource population at any give time step.
def dCR_dt(pops, t=0):

    R = pops[0]
    C = pops[1]
    dRdt = r * R - a * R * C
    dCdt = -z * C + e * a * R * C

    return sc.array([dRdt, dCdt])

r = float(first)
a = float(second)
z = float(third)
e = float(fourth)

t = sc.linspace(0, 15, 1000) 
R0 = 10
C0 = 5
RC0 = sc.array([R0, C0])
pops, infodict = integrate.odeint(dCR_dt, RC0, t, full_output = True)

f1 = p.figure()
p.plot(t, pops[:,0], 'g-', label='Resource density') #Plot
p.plot(t, pops[:,1], 'b-', label = 'Consumer densioty')
p.grid()
p.legend(loc='best')
p.xlabel('Time')
p.ylabel('Population density')
p.title('Consumer-Resource population dynamics')

f1.savefig('../results/LV_model3.pdf') #save figure

f2 = p.figure()
p.plot(pops[:,0], pops[:,1], 'r-')
p.grid()
p.xlabel('Resource density')
p.ylabel('Consumer density')
p.title('Consumer-Resource population dynamics')
f2.savefig('../results/LV_model4.pdf')**********************************************************************

Testing LV2.py...

LV2.py is a Python script file;

checking for docstrings...

Found one or more docstrings and functions

Missing docstring, either in one or functions and/or at the script level

Current Points = 94.0

Output (only first 500 characters): 

**********************************************************************

**********************************************************************

Encountered error (or warning):
Traceback (most recent call last):
  File "LV2.py", line 14, in <module>
    script, first, second, third, fourth = argv
ValueError: not enough values to unpack (expected 5, got 1)

======================================================================
======================================================================
Finished running scripts

Ran into 4 errors

======================================================================
======================================================================

FINISHED WEEKLY ASSESSMENT

Current Points for the Week = 94.0

NOTE THAT THESE ARE POINTS, NOT MARKS FOR THE WEEK!