Starting weekly assessment for Amy, Week6

Current Points = 100

Note that: 
(1) Major sections begin with a double "====" line 
(2) Subsections begin with a single "====" line 
(3) Code output or text file content are printed within single "*****" lines 

======================================================================
======================================================================
Your Git repo size this week is about 250.86 MiB on disk 

PART 1: Checking project workflow...

Found the following directories in parent directory: Week6, Week1, Week7, Assessment, Week5, Week2, Week9, Week4, .git, Miniproject, Week3, Project

Found the following files in parent directory: .gitignore, README.md, .DS_Store

Checking for key files in parent directory...

Found .gitignore in parent directory, great! 

Printing contents of .gitignore:
**********************************************************************
*~ 
*.tmp
**********************************************************************

Found README in parent directory, named: README.md

Printing contents of README.md:
**********************************************************************
# CMEE README

My CMEE Coursework Repository

This repository contains the coursework for my CMEE MRes at Imperial College London. The programs therein use shell scripting, python and R. 

Work is divided into week-specified subdirectories (Week1/Week2...) except for where indicated.

Week 1

Practicals using command line and shell scripting only. Sandbox contains practise files. Code contains shell scripts. Data contains data files used with shell scripts. Plus README.md. 

Week 2

Biological computing in Python I. Including: using data structures, writing code, control flow tools, comprehensions, debugging etc.

Week 3

Biological computing in R. Including: Variable types, data structures, manipulating data, control flow tools, vectorisation, data management and visualisation.

Week 4

Statistics in R. Including: Basic statistics for ecology and evolution, with a focus on applicability. Mostly parametric tests (descriptive statistics, t-test, ANOVA, correlations, linear models, hypothesis testing).

Week 5

Spatial Analyses and Geographic Information Systems. Including: GIS data types, obtaining and handling GIS data, creating maps, basic data analyses and hypothesis testing in the spatial domain.

Week 6

Genomics and Bioinformatics. Including: understanding genomic data collection methods, how to choose data collection technique, genomic databases, genetic structure within/between populations, how to characterise and interpret results of common analyses such as STRUCTURE and PCA.

Week 7

Biological Computing in Python II. Including: program testing, debugging and documentation, retrieving, managing and analyzing data from local and remote databases, automate file handling, string manipulation and run shell scripts, efficient numerical analyses, patching together R and Python scripts and functions.

Miniproject (Week 8)

Selected own dataset out of selection of three. Carried out computationally intensive analysis that includes elements of shell scripting, R & Python, addressing questions involving data processing and model fitting, writing up and compiling a meaningful report on the analysis.

Week 9

High Performance Computing. Including: develop an advanced understanding of programming in R, principles of High Performance Computing.

Project

Working folder for dissertation project, including project proposal.


**********************************************************************

======================================================================
Looking for the weekly directories...

Found 8 weekly directories: Week1, Week2, Week3, Week4, Week5, Week6, Week7, Week9

The Week6 directory will be assessed 

======================================================================
======================================================================
PART 2: Checking weekly code and workflow...

======================================================================
Assessing WEEK6...

Found the following directories: Code, Data, Results

Found the following files: README.md, .DS_Store

Checking for readme file in weekly directory...

Found README in parent directory, named: README.md

Printing contents of README.md:
**********************************************************************
# CMEE README WEEK 6

Genomics and Bioinformatics (4/11/19 - 8/11/19)
Genetic data contain information about who organisms are, their relationships to other organisms, their population histories, and their histories of adaptation. Thus, genetic data and genetic techniques are central to addressing many questions in evolution, ecology, and conservation. New technologies allow for genetic characterization at the genomic level, and these data allow for an understanding of population processes at resolutions not possible in the past. The goal of this module was to introduce students to the types of questions that can be addressed with genomic data, and the methodologies that are available for answering these questions.
**********************************************************************

Found following files in results directory: .gitkeep...

Found 4 code files: Genom1.R, Genom3.R, Genom4.R, Genom2.R

Found the following extra files: .DS_Store
0.5 pt deducted per extra file

Current Points = 99.5

======================================================================
Testing script/code files...

======================================================================
Inspecting script file Genom1.R...

File contents are:
**********************************************************************
#Amy Solman amy.solman19@imperial.ac.uk
#Monday 4th November
#Genomics and Bioinformatics Day One


rm(list=ls())

data <- read.csv("../Data/bears.csv", stringsAsFactors=FALSE, colClasses=rep("character", 1000), header=FALSE)

dim(data)

# install.packages("adegenet")
# install.packages("hierfstat")
# install.packages("pegas")
# library(adegenet)
# library(hierfstat)
# library(pegas)
# 
# locus <- data[, -c(1, 2, 3, 4, 17:3086)]    
# colnames(locus) <- gsub("\\.", "_", colnames(locus)) # locus names can't have "."
# ind <- as.character(Mydata$tree_id) # labels of the individuals
# population <- as.character(Mydata$state) # labels of the populations
# Mydata1 <- df2genind(locus, ploidy = 2, ind.names = ind, pop = population, sep = "")
# Mydata1

# Write a script in R that complete all the following tasks:
#   
#identify which positions are SNPs (polymorphic, meaning that they have more than one allele)

#This stores the indexes of the polymorphic alleles
snps <- c() #create empty vector
for (i in 1:ncol(data)) {
  if 
  (length(unique(data[,i]))==2)
    snps <- c(snps, i)
}

cat("\nNumber of SNPs is:", length(snps)) 

#reduce the data set to polymorphic alleles only
data <- data[,snps]
dim(data)

#calculate, print and visualise allele frequencies for each SNP

# install.packages("tidyverse")
# 
# library(tidyverse) 
# 
# data %>% 
#   as.tibble() %>% 
#   count(data[,1])

allele_frq <- c() #create empty vector
for (i in 1:ncol(data)) { #for each column in the data
  alleles <- sort(unique(data[,i])) # alleles = ordered uniqe data values in column

 cat("\nSNP", i, "with alleles", alleles)

 freq <- length(which(data[,i]==alleles[1])) / nrow(data)
 cat(" and allele frequency of the first allele", freq)
 
 allele_frq <- c(allele_frq, freq)
}

myData <- data.frame(first_allele=alleles, frequency_first_allele=allele_frq, frequency_second_allele=1-allele_frq)
print(myData)

hist(allele_frq)


#calculate and print genotype frequencies for each SNP
#How may times does each two rows have the same alleles 
#For each column, if the two rows match in a row = homozygote

nsamples <- 20 #we have 20 samples
for (i in 1:ncol(data)) { #for each column in our data
  
  ### alleles in this SNPs
  alleles <- sort(unique(data[,i])) #store our unique values in this list
  cat("\nSNP", i, "with alleles", alleles)
  
  ### as before, I can choose one allele as "reference"
  ### genotypes are Allele1/Allele1 Allele1/Allele2 Allele2/Allele2
  genotype_counts <- c(0, 0, 0) #make data frame to take three columns of data
  
  for (j in 1:nsamples) {
    ### indexes of genotypes for individual j
    genotype_index <- c( (j*2)-1, (j*2) ) #
    ### count the Allele2 instances
    genotype <- length(which(data[genotype_index, i]==alleles[2])) + 1
    ### increase the counter for the corresponding genotype 
    genotype_counts[genotype] <- genotype_counts[genotype] + 1
  }
  cat(" and genotype frequencies", genotype_counts)
}

#calculate (observed) homozygosity and heterozygosity for each SNP

nsamples <- 20
for (i in 1:ncol(data)) {
  
  ### alleles in this SNPs
  alleles <- sort(unique(data[,i]))
  cat("\nSNP", i, "with alleles", alleles)
  
  ### as before, I can choose one allele as "reference"
  ### genotypes are Allele1/Allele1 Allele1/Allele2 Allele2/Allele2
  genotype_counts <- c(0, 0, 0)
  
  for (j in 1:nsamples) {
    ### indexes of genotypes for individual j
    genotype_index <- c( (j*2)-1, (j*2) )
    ### count the Allele2 instances
    genotype <- length(which(data[genotype_index, i]==alleles[2])) + 1
    ### increase the counter for the corresponding genotype
    genotype_counts[genotype] <- genotype_counts[genotype] + 1
  }
  cat(" and heterozygosity", genotype_counts[2]/nsamples, "and homozygosity", 1-genotype_counts[2]/nsamples)
}

#calculate expected genotype counts for each SNP and test for HWE
# 

nonHWE <- c() #to store indexes (locations) of SNPs deviating from HWE
nsamples <- 20
for (i in 1:ncol(data)) {
  #alleles in this SNPs 
  alleles <- sort(unique(data[,1]))
  cat("\nSJNP", i)
  #as before I can choose on allele as "reference"
  #frequency (of the second allele)
  freq <- length(which(data[,i]==alleles[2]))/nrow(data)
  #from the frequency, I can calculate the expected genotype counts under HWE
  genotype_counts_expected <- c( (1-freq)^2, 2*freq*(1-freq), freq^2) * nsamples
  #genotypes are Allele1/Allele1, Allele1/Allele2, Allele2/Allele2
  genotype_counts <- c(0, 0 , 0)
  for (j in 1:nsamples) {
    #indexes of genotypes for individual j
    genotype_index <- c((j*2)-1, (j*2))
    #count the allele2 instances
    genotype_counts[genotype] + 1
  }
  #test for HWE: calculate chi^2 statistic
  chi <- sum((genotype_counts_expected - genotype_counts)^2 / genotype_counts_expected)
  #pvalue
  pv <- 1 - pchisq(chi, df=1)
  cat("with pvalue for test against HWE, pv")
  #retain SNPS with pvalue <0.05
  if (pv <-0.05) nonHWE <- c(nonHWE, i)
  
}

#calculate, print and visualise inbreeding coefficient for each SNP deviating from HWE

#assuming we ran the code for point 5, we already have the SNPs deviating 
F <- c()
nsamples <- 20
for (i in nonHWE) {
  #alleles in this SNPs
  alleles <- sort(unique(data[,i]))
  cat("\nSNP", i)
#as before, I can choose one allele as "reference"
#frequency of the second allele
  frq <- length(which(data[,i]==alleles[2]))/
    nrow(data)
  #from the frequency, I can calculate the expected genotype counts under HWE
  genotype_counts_expected <- c((1-freq)^2, 2*freq*(1-freq), freq^2) * nsamples
  #genotypes are Allele1/Allele1, Allele1/Allele2, Allele2/Allele2
  genotype_counts <- c(0, 0, 0)
  for (j in 1:nsamples) {
    #indexes of genotypes for individual j
  genotype_index <- c((j*2)-1, (j*2))
  #count the Allele2 instances
  genotype <- length(which(data[genotype_index, i]==alleles[2])) + 1
  #increase the counter for the corresponding genotype
  genotype_counts[genotype] <- genotype_counts[genotype] + 1
  }
  #calculate inbreeding coefficient
  inbreeding <- (2*freq*(1-freq)-(genotype_counts[2]/nsamples)) / (2*freq*(1-freq))
  F <- c(F, inbreeding)
  cat(" with inbreeding coefficient", inbreeding)
  
}

#plot
#hist(F)
#plot(F, type="h")
**********************************************************************

Testing Genom1.R...

Output (only first 500 characters): 

**********************************************************************
[1]    40 10000

Number of SNPs is: 100[1]  40 100

SNP 1 with alleles A C and allele frequency of the first allele 0.55
SNP 2 with alleles C G and allele frequency of the first allele 0.975
SNP 3 with alleles A C and allele frequency of the first allele 0.625
SNP 4 with alleles A T and allele frequency of the first allele 0.025
SNP 5 with alleles A T and allele frequency of the first allele 0.975
SNP 6 with alleles C G and allele frequency of the first allele 0.45
SNP 7 with alleles A G and alle
**********************************************************************

Code ran without errors

Time consumed = 1.00761s

======================================================================
Inspecting script file Genom3.R...

File contents are:
**********************************************************************
#Amy Solman amy.solman19@imperial.ac.uk
#Monday 7th November
#Genomics and Bioinformatics Day Four

##########COALESCENCE##########
#A retrospective, stochastic model of population genetics that relates
#genetic diversity in a sample to demographic history of the population
#from which it was taken. It is a model of the effect of genetic drfit viewed
#backwards in time on the genealogy of a decedence.
#Coalescene involves tracking the ancestory of a sampel between two generations.
#If two individual gene copies have the same parent in the previous generation,
#we say that the ancestral lineage representing these two individual coalesced.
#It's important to remember that when talking about 'individuals'
#we are talking about a single gene/allele, as if from a haploid species
#So when genes are passed down they do so in one chromosome, with one complete 
#set of genes/alleles - not two (diploid)
#Anyway, the alleles we're looking at have a common ancestor and a coalescent
#event has occured.
#The ancestry of an individual gene copy is represented by a line (or edge).
#The time until two lineages find a most recent common ancestor (MRCA)
#is called coalescence time. How can we find coalescence time?

#COALESCENCE IN A SAMPLE OF TWO GENE COPIES
#As there are 2N potential parents 'chosen' with equal probability,
#the probability of two gene copies having the same parent in the 
#previous generation is 1/(2N).
#The probability that two gene copies did not have the same parent in the 
#previous generation is 1-1/(2N)

#T = time between each coalescence event


#Practical on coalescence theory
#You are interested in the size of two populations of Atlantic 
#killer whales, one migrating towards a Northern geogrpahical 
#location and one towards a Southern location. These two populations
#share a recent common ancestor but their current population size is 
#hypothesised to be different. To test this hypothesis, you collect 10 
#(diploid = 20 chromosone) samples from the Northern population and 10
#from the Southern population. For each sample, you obtained a genomic 
#sequence of 50kbp (50,000 base pairs). The data is stores in .csv files
#names killer_whale_North.csv and killer_whale_South. Each allele is 
#encoded as 0 or 1 for the ancestral and derived state, respectively.

#1) Estimate the effective population size for each population, using
#both the Watterson's and Tajima's estimator of "theta" assuming a 
#mutation rate of 1x10^{-8}. Discuss the difference between values of
#"theta" using different estimators.

rm(list=ls())
#setwd("/Users/amysolman/Documents/CMEECourseWork/Week6/Data")

len <- 50000 #The number of basepairs 

#Since the data is encoded as 0 and 1 it is better to store as a matrix
North <- as.matrix(read.csv("../Data/killer_whale_North.csv",
                     stringsAsFactors = F, header = F, colClasses=rep("numeric", len)))
South <- as.matrix(read.csv("../Data/killer_whale_South.csv", 
                     stringsAsFactors=FALSE, header=FALSE, colClasses=rep("numeric", len)))

##########IT WAS NOT NECESSARY TO FIND THE POLYMORPHIC ALLELES BEFORE FINDING EFFECTIVE POPULATIONS SIZE##########
#Firstly, let's save the index's of polymorphic alleles to an empty vector
# snps1 <- c()
# for (i in 1:ncol(North)){
#   if
#   (length(unique(North[,i]))==2)
#     snps1 <- c(snps1, i)
# }
# 
# #reduce the data set to polymorphic alleles only
# North_SNPS <- North[,snps1]
# 
# #And again for our South population...
# snps2 <- c()
# for (i in 1:ncol(South)) {
#   if
#   (length(unique(South[,i]))==2)
#     snps2 <- c(snps2, i)
#   }
# 
# South_SNPS <- South[,snps2]

##########TAJIMA'S ESTIMATOR##########
#Perfect, now let's use Tajima's estimator of "theta" to estimate the effective population size 
#assuming a mutation rate of 1x10^{-8}.
#Firstly, what is "theta"? "Theta" is the expected number of mutations between two individuals 

#For the Northern Whale!
n <- nrow(North) #number of rows = number of chromosomes
pi_N <- 0 #set pairwise difference vector to zero
for (i in 1:(n-1)) { #for each row in row 1 to (row number -1)
  for (j in (i+1):n) { #for each next row going down to the end
    pi_N <- pi_N + #add to the pairwise difference vector
sum(abs(North[i,]-North[j,])) #the sum of the absolute value of one column from another
  }
}

#Finds the average of all the pairwide comparisons
pi_N <- pi_N / ((n*(n-1))/2) #total difference of each pairwise row divided by number of iterations
#number of iterations = number of rows multiplied by number of rows minus 1 divided by 2

#Let's do the same for the Southern Whale!

n <- nrow(South) 
pi_S <- 0 
for (i in 1:(n-1)) {
  for (j in (i+1):n) {
    pi_S <- pi_S +
      sum(abs(South[i,]-South[j]))
  }
}

pi_S <- pi_S /((n*(n-1))/2) 

#So, now we have the average pairwise differences for the Northern and Southern whale pos.
#Let's use these to find estimates of Ne (effective population size)

Ne_N_pi <- pi_N / (4 * 1e-8 * len) #Here we divide the average pairwise differences of the population by the 
#assumed mutation rate multiplied by number of base pairs
Ne_S_pi <- pi_S / (4 * 1e-8 * len)

##########WATTERSON'S ESTIMATOR##########
#Now we'll look at using Watterson's estimator for find the effective
#population sizes for Northern and Southern whales
#Wattersons differs from Tajima's as it requires a count of 
#segregation sites (a.k.a polymorphic allele indexes)

#For this we'll have to calculate the number of polymorphic alleles
#This is the same as we did earlier, just using the apply function
freqs <- apply(X=North, MAR=2, FUN=sum)/nrow(North) #Here we use the apply function
#this returns a vector of values (freqs) obtained by applying a function 
#to our matrix. Here our matrix is North, our MAR(GIN) tells us to look at the 
#columns (rows would be 2). FUN(CTION) tells us to sum the values. 
#So, all in all, this we have created an apply function that sums the values in
#the columns of our North matrix and stores the results in the vector freqs

snps_N <- length(which(freqs>0 & freqs<1)) # we then ask, how many (length)
#of the values in the vector (freqs) is it true the value is greater than 0 and less than 1
#The number of snps for N is then stored in a vector

#Next we'll calculate the Watterson's estimator
n <- nrow(North)
watt_N <- snps_N / sum(1/seq(1,n-1))
#The estimator is the number of polymorphic alleles divided by the sum of
#1 dividied by....'seq' generates a sequence of numbers, here from 1 to 1 less than the sample size
#which here is the number of rows (20 chromosomes for 10 individuals)

#Let's repeat again for South
freqs <- apply(X=South, MAR=2, FUN=sum)/nrow(South)
snps_S <- length(which(freqs>0 & freqs<1))

#And calculate Watterson's estimator
n <- nrow(South)
watt_S <- snps_S / sum(1/seq(1,n-1)) #So we divide 1 by 1, then 1 by 2, then 1 by 3 and so on until 19
#then add those together and divide the number of polymorphic alleles by them

#Estimates of effective population size from Watterson's estimator
Ne_N_watt <- watt_N / (4 * 1e-8 * len)
Ne_S_watt <- watt_S / (4 * 1e-8 * len)

cat("\nThe North population has estimates of effective population size of",
    Ne_N_pi, "and", Ne_N_watt)
cat("\nThe Southern population has estimates of effective population size of",
    Ne_S_pi, "and", Ne_S_watt)

#Discuss the differences between the values of "theta" using different estimators.
#'Theta' is the amount of mutations between individuals, the amount of genetic variation between
#individuals of a population
#The expected number of nucleotide differences between two sequences is the expected 
#number of mutations = 'Theta' = estimated number of pairwise differences
#Using Tajima's estimator the Northern whales had 9.27 average pairwise differences 
#and Southern whale had 5.44 average pairwise differences.
#Using Watterson's estimator

#TWO
#Calculate and plot the (unfolded) site frequency spectrum for each population
#and discuss it.

#Northern population
n <- nrow(North)
sfs_N <- rep(0, n-1)
#Allele frequencies
derived_freqs <- apply(X=North, MAR=2, FUN=sum)
#The easiest (but slowest) thing to do would be to loop over
#all possible allele frequencies and count the occurences
for (i in 1:length(sfs_N)) sfs_N[i] <- length(which(derived_freqs==i))

#Southern population
n <- nrow(South)
sfs_S <- rep(0, n-1)
#Allele frequencies
derived_freqs <- apply(X=South, MAR=2, FUN=sum)
for (i in 1:length(sfs_S)) sfs_S[i] <- length(which(derived_freqs==i))

#Plot
barplot(t(cbind(sfs_N, sfs_S)), beside=T, names.arg=seq(1,nrow(South)-1,1), legend=c("North", "South"))

barplot(t(cbind(sfs_N, sfs_S)), beside=T, names.arg=seq(1,nrow(South)-1,1), legend=c("North", "South"))

cat("\nThe population with the greater population size has
    a higher proportion of singletons, as expected.")

#Bonus Question
#Calculate the joint site frequency spectrum; in other words, for each site
#you need to calculate the joint allele frequency (in one population
#and in the other) and fill in a corresponding matrix of count which will 
#be the joint 2D site frequency spectrum

sfs <- matrix(0, nrow=nrow(North)+1, ncol=nrow(South)+1)
for (i in 1:ncol(North)) {
  freq_N <- sum(North[,i])
  freq_S <- sum(South[,i])
  
  sfs[freq_N+1, freq_S+1] <- sfs[freq_N+1, freq_S+1] + 1
}

sfs[1,1] <- NA

image(t(sfs))

**********************************************************************

Testing Genom3.R...

Output (only first 500 characters): 

**********************************************************************

The North population has estimates of effective population size of 4634.211 and 4650.849
The Southern population has estimates of effective population size of 2721.053 and 845.6088
The population with the greater population size has
    a higher proportion of singletons, as expected.
**********************************************************************

Code ran without errors

Time consumed = 8.44823s

======================================================================
Inspecting script file Genom4.R...

File contents are:
**********************************************************************
#Amy Solman amy.solman19@imperial.ac.uk
#Monday 8th November
#Genomics and Bioinformatics Day Five

#Practical on population subdivision and demographic inferences

rm(list=ls())
len <- 2000
#setwd("/Users/amysolman/Documents/CMEECourseWork/Week6/Code")

Haplotypes <- as.matrix(read.csv("../Data/turtle.csv",
                                 stringsAsFactors = F, header = F, colClasses=rep("numeric", len)))
Genotypes <- as.matrix(read.csv("../Data/turtle.genotypes.csv",
                                stringsAsFactors = F, header = F, colClasses = rep("numeric", len)))
dim(Genotypes) #40 rows (individuals 0, 1 or 2) by 2000 polymorphic alleles



#You are interested in inferring the history of a population of 
#sea turtles
#You collected some DNA data from 40 (diploid) individuals from 4 different
#locations (A, B, C, D). You have 10 individuals for each
#location. For each sample, you have access to 2000 SNPs (not base pairs, only
#the polymorphic sites). The data on alleles/haplotypes is stored in turtle.csv
#(80 rows) while the data on genotypes (40 rows) is stored in
#turtle.genotypes.csv. Genotypes are encoded as 0/1/2 as homozygous for the 
#ancestral, heterozygous, homozygous for the derived allele, respectively.

#1. Test whether there is a population subdivision in this sample and, if so, 
#at which extent.

#So here we are asking, is there genetic subdivision within our sample and between the four populations?

#There are several ways of doing it. (A) You may want to infer a tree from
#genetic distances. In R you can use dist to calculate eucledian distances between 
#individuals based on their genotypes. From the resulting distance
#matrix you can infer a tree using tree <- hclust(distance_matrix) and then plot it 
#with plot(tree). (B) You can do a Principal Component Analysis. In R you can use
#pca <- prcomp(data...) to calculate principal components which will be stored in 
#pca$x. You can plot the first two/three components afterwards. For this analysis 
#is it better to consider only SNPs with an allele frequency of at least 0.05.
#(C) You can calculate everage FST across all SNPs for each pair of subpopulation and 
#see whether it is larger than zero, and whether it changes for each comparison.
#My suggestion would be to start with point (C) as discussed during the lecture.

#Assign a name for each location
locations <- rep(c("A","B","C","D"), each=10)
#we use rep here because we want to concantenate the character values A, B, C, D
#to the function 'location' 10 times each

#To test whether this a population subdivision we can do several things
#for instance, we can build a tree of all samples and check
#whether we observe some cluster
#we can do this by first building a distance matrix and then a tree

distance <- dist(Genotypes) #here we're passing the genotypes data
#through a distance matrix computation. What in the heck does that mean?
#The distance matrix is comprised of distance measures for each pair of
#cases in the data set. A distance measure is a measure of similarity 
#between two cases, based on a numeric set of values.
#Default distance measure is the Euclidean Distance (ordinary straight line distance
#in geometric space)

tree <- hclust(distance) #What does hclust do? hierarchical clustering
#Here we are preforming a hierarchical cluster analysis on a set of dissimilarities
#(our distance matrix). Basically, if we want to plot a dendrogram with our data
#that is a graph that shows hierarchical relationships between out data
#we need to create a distance matrix, and then apply hierarchical clustering

plot(tree, labels = locations)

#Or we can do a PCA
#We can filter out our low-frequency variants first

colors <- rep(c("blue", "red", "yellow", "green"), each=5)


index <- which(apply(FUN=sum, X=Genotypes, MAR=2)/(nrow(Genotypes)*2)>0.03)

pca <- prcomp(Genotypes[,index], center=T, scale=T)

summary(pca)

plot(pca$x[,1], pca$x[,2], col=colors, pch=1)
legend("right", legend=sort(unique(locations)), col=unique(colors), pch=1)

calcFST <- function(pop1, pop2) {
  #only for equal sample sizes
  fA1 <- as.numeric(apply(FUN=sum, X=pop1, MAR=2)/
nrow(pop1))
  fA2 <- as.numeric(apply(FUN=sum, X=pop2, MAR=2)/
nrow(pop2))
  FST <- rep(NA, length(fA1))
  
  for (i in 1:length(FST)) {
    
    HT <- 2 * ( ( fA1[i] + fA2[i]) / 2 ) * (1 -
((fA1[i] + fA2[i]) / 2) )
    HS <- fA1[i] * (1 - fA1[i]) + fA2[i] * (1 - 
fA2[i])
    FST[i] <- (HT - HS) /HT
  }
  FST
}

snps <- which(apply(FUN=sum, X=Haplotypes, MAR=2)/
  (nrow(Haplotypes))>0.03)

cat("\nFST value (average):",
"\nA vs B", mean(calcFST(Haplotypes[1:20,snps],
Haplotypes[21:40,snps]),na.rm=T),
"\nA vs C", mean(calcFST(Haplotypes[1:20,snps],
Haplotypes[41:60,snps]),na.rm=T),
"\nA vs D", mean(calcFST(Haplotypes[1:20,snps],
Haplotypes[61:80,snps]),na.rm=T),
"\nB vs C", mean(calcFST(Haplotypes[1:20,snps],
Haplotypes[41:60,snps]),na.rm=T),
"\nB vs D", mean(calcFST(Haplotypes[1:20,snps],
Haplotypes[61:80,snps]),na.rm=T),
"\nC vs D", mean(calcFST(Haplotypes[1:20,snps],
Haplotypes[61:80,snps]),na.rm=T),"\n")

#These values indicate a certain degree of population subdivision

#Or we can calculate FST between locations from haplotype

#2. Assess whether there has been isolation by distance in this species, 
#knowing that the geographical distance of each population
#from a putative origin is: A (5km), B (10km), C (12km), D (50km).

#You can test whether genetic distance correlated with geographic distance. 

#2) There is no evidence of isolation by distance, but instead of admixture

#Bonus question:
#assuming that we have access to reference information from 3 known subpopulations
#in the area, how would you perform an admixture analysis in this sample? Allele 
#frequency for a set of markers for 3 subpopulations are stored
#in turtle_markers.csv, with the first column indicating that the genomic position 
#of the marker and the other columns showing the derived allele frequency at each 
#subpopulation. How would you do that?



**********************************************************************

Testing Genom4.R...

Output (only first 500 characters): 

**********************************************************************
[1]   40 2000
Importance of components:
                           PC1     PC2     PC3    PC4     PC5     PC6     PC7
Standard deviation     18.2017 12.4864 10.1435 9.7565 7.27634 4.40556 3.93960
Proportion of Variance  0.3958  0.1863  0.1229 0.1137 0.06326 0.02319 0.01854
Cumulative Proportion   0.3958  0.5821  0.7050 0.8187 0.88200 0.90519 0.92374
                           PC8     PC9   PC10    PC11    PC12    PC13    PC14
Standard deviation     3.13567 3.04228 2.7601 2.70524 2.55631 2.38355 2
**********************************************************************

Code ran without errors

Time consumed = 0.42527s

======================================================================
Inspecting script file Genom2.R...

File contents are:
**********************************************************************
#Amy Solman amy.solman19@imperial.ac.uk
#Monday 5th November
#Genomics and Bioinformatics Day Two

rm(list=ls())
#setwd("/Users/amysolman/Documents/CMEECourseWork/Week6/Data")

#Load the three species genomic data files

WestBand <- read.csv("../Data/western_banded_gecko.csv", 
                 stringsAsFactors=FALSE, colClasses=rep("character", 1000), header=FALSE)
dim(WestBand)
BentToed <- read.csv("../Data/bent-toed_gecko.csv", 
                              stringsAsFactors=FALSE, colClasses=rep("character", 1000), header=FALSE)
dim(BentToed)
Leopard <- read.csv("../Data/leopard_gecko.csv", 
                     stringsAsFactors=FALSE, colClasses=rep("character", 1000), header=FALSE)
dim(Leopard)

#Firstly, calculate the genetic divergency of each pair of species to assign
#leaves to the proposed topology (which pair is most divered so we know which species
#diverged first)

#How genetically similar are WestBand and BentToed
#For each column of WestBand how similar is it to the same band in Bent Toed?

#start by creating two empty vectors, one for total data values (sits) and one for 
#total different data values (sites divergent). So, we can divide the number of divergent values by
#the number of total values

sites_total <- 0 #set the number of total sites (columns) to 0
sites_divergent <-  0 #set the numnber of divergent sites (columns) to 0

#We need to remove the SNPs within each species - what does this mean?
#SNPs are single nucleotide polymorphisms or 'snips'. These are where alleles in 
#diploid individuals are not the same, so instead of CC, AA, TT, having a pair of matching
#nucleotides, they have polymorphic nucleotides CA or TG etc. These are NOT fixed 
#within the population, they are individual mutations that will not help us
#understand how similar whole species are. We want to look exclusively at the genetic
#information that it fixed within each species to draw a useful comparison.
#So let's remove the columns of data that do not have matching alleles for that
#individual.


for (i in 1:ncol(WestBand)) { #for each column of values (alleles) in WestBand
  if 
  (length(unique(WestBand[,i]))==1 & #if the number (length) of unique values in the column of the first species equals 1 and
    length(unique(BentToed[,i]))==1) {#the number (length) of unique values in the column of the second species equals 1
sites_total <- sites_total + 1 # adds up the number of non-SNP sites for both species

#if different, then it's a divergent site
 if 
(WestBand[1,i] != BentToed[1,i]) # if the first row and any columns of species one and different from species two
   sites_divergent <- sites_divergent + 1 # adds up the number of sites that are different between the two species
}
}
#So if we have the locations of the non-SNP data for both species, and the places that they are different
#we can calculate the divergence rate

divergence_rate_WB_BT <- sites_divergent / sites_total
print(divergence_rate_WB_BT) #0.0037

#Now we'll repeat this for each pair - WestBand and Leopard

sites_total <- 0
sites_divergent <- 0

for (i in 1:ncol(WestBand)) {
  if
  (length(unique(WestBand[,i]))==1 &
   length(unique(Leopard[,i]))==1) {
    sites_total <- sites_total + 1 
      
  if
  (WestBand[1,i] != Leopard[1,i])
    sites_divergent <- sites_divergent + 1
    }
}

divergence_rate_WB_L <- sites_divergent / sites_total
print(divergence_rate_WB_L) # 0.0088

#Now repeat for BentToed and Leopard

sites_total <- 0
sites_divergent <- 0

for (i in 1:ncol(BentToed)) {
  if
  (length(unique(BentToed[,i]))==1 &
   length(unique(Leopard[,i]))==1) {
    sites_total <- sites_total + 1
    
    if (BentToed[1,i] != Leopard[1,i])
    sites_divergent <- sites_divergent + 1
  }
}

divergence_rate_BT_L <- sites_divergent / sites_total
print(divergence_rate_BT_L) # 0.0091

#We conclude that WestBanded and BentToed are most closely related, with Leopard as an outlier. 
#Leopard is most closely related to the WestBanded to we infer that the Leopard diverged fromt he WestBanded
#at 30mya, then BentToed diverged from WestBanded 15mya.

#estimate mutation rate per site (column) per year (30mya)
#mutation rate is the divergence rate of two species,
#divided by 2 x number of years since divergence

mutation_rate_WB_L_per_my <- divergence_rate_WB_L/(2*30)
print(mutation_rate_WB_L_per_my)

mutation_rate_BT_L_per_my <- divergence_rate_BT_L/(2*30)
print(mutation_rate_BT_L_per_my)

mean_mutation_rate <- (mutation_rate_WB_L_per_my+mutation_rate_BT_L_per_my) /2
print(mean_mutation_rate)

#now estimate divergence time = 
# genetic difference of two species / 2 times mutation rate

EDT_WB_L <- divergence_rate_WB_L/(2*mutation_rate_WB_L_per_my)
print(EDT_WB_L)

EDT_WB_BT <- divergence_rate_WB_BT/(2*mean_mutation_rate)
print(EDT_WB_BT) #we can estimate the divergence time for these
#species by using a mean mutation rate

EDT_BT_L <- divergence_rate_WB_L/(2*mutation_rate_BT_L_per_my)
print(EDT_BT_L)

cat("\nThe most likely species tree is L:(W:B).")








**********************************************************************

Testing Genom2.R...

Output (only first 500 characters): 

**********************************************************************
[1]    20 20000
[1]    20 20000
[1]    20 20000
[1] 0.003672032

**********************************************************************

Code ran without errors

Time consumed = 10.01299s

======================================================================
======================================================================
Finished running scripts

Ran into 0 errors

======================================================================
======================================================================

FINISHED WEEKLY ASSESSMENT

Current Points for the Week = 99.5

NOTE THAT THESE ARE POINTS, NOT MARKS FOR THE WEEK!